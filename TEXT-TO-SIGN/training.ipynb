{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb8dd8f8",
   "metadata": {},
   "source": [
    "# Text2Sign â€” GAN-NAT Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8672724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud auth login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161e8669",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud storage cp -r gs://ghsl-model-artifacts/text2sign /content/\n",
    "!gcloud storage cp -r gs://ghsl-datasets/sample_dataset /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e72cb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio transformers pandas numpy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf696da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16\n",
      "drwxr-xr-x 1 root root 4096 Nov 20 14:30 .\n",
      "drwxr-xr-x 1 root root 4096 Dec 10 04:06 ..\n",
      "drwxr-xr-x 4 root root 4096 Nov 20 14:30 .config\n",
      "drwxr-xr-x 1 root root 4096 Nov 20 14:30 sample_data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"âœ… Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20331f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "PROCESSED_META = \"proc/text2sign_processed_metadata.csv\"\n",
    "FEATURE_DIR = \"features/text2sign_pose\"\n",
    "GLOBAL_STATS = \"proc/text2sign_global_stats.npz\"\n",
    "MAX_SEQ_LEN = 128   # allow longer than preprocessing trim; we can pad\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# Text encoder\n",
    "TEXT_MODEL = \"distilbert-base-uncased\"\n",
    "TEXT_DIM = 768\n",
    "TEXT_PROJ_DIM = 256\n",
    "\n",
    "# Generator / Discriminator\n",
    "POSE_DIM = 33*4 + 2*21*3 + 94*3\n",
    "LATENT_DIM = 64\n",
    "HIDDEN_DIM = 256\n",
    "NUM_LAYERS = 4\n",
    "LENGTH_BINS = list(range(10, 201, 2))  # candidate lengths\n",
    "\n",
    "# Optimization\n",
    "LR_G = 1e-4\n",
    "LR_D = 5e-5\n",
    "BETA1, BETA2 = 0.5, 0.9\n",
    "LAMBDA_REC = 1.0\n",
    "LAMBDA_ADV = 1.0\n",
    "LAMBDA_GEO = 0.2\n",
    "GRAD_CLIP = 1.0\n",
    "EPOCHS = 50\n",
    "CHECKPOINT_DIR = Path(\"checkpoints_text2sign\")\n",
    "CHECKPOINT_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b294fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 55512\n",
      "drwxr-xr-x 1 root root     4096 Nov 20 14:30 .\n",
      "drwxr-xr-x 1 root root     4096 Nov 20 14:30 ..\n",
      "-rwxr-xr-x 1 root root     1697 Jan  1  2000 anscombe.json\n",
      "-rw-r--r-- 1 root root   301141 Nov 20 14:30 california_housing_test.csv\n",
      "-rw-r--r-- 1 root root  1706430 Nov 20 14:30 california_housing_train.csv\n",
      "-rw-r--r-- 1 root root 18289443 Nov 20 14:30 mnist_test.csv\n",
      "-rw-r--r-- 1 root root 36523880 Nov 20 14:30 mnist_train_small.csv\n",
      "-rwxr-xr-x 1 root root      962 Jan  1  2000 README.md\n"
     ]
    }
   ],
   "source": [
    "class Text2SignDataset(Dataset):\n",
    "    def __init__(self, meta_path, feature_dir, max_seq_len=MAX_SEQ_LEN, normalize=True):\n",
    "        self.df = pd.read_csv(meta_path)\n",
    "        self.feature_dir = Path(feature_dir)\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.normalize = normalize\n",
    "\n",
    "        stats = np.load(GLOBAL_STATS) if normalize and os.path.exists(GLOBAL_STATS) else None\n",
    "        self.mean = stats['feature_mean'] if stats is not None else None\n",
    "        self.std = stats['feature_std'] if stats is not None else None\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(TEXT_MODEL)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        feat_path = Path(row['feature_path'])\n",
    "        arr = np.load(feat_path)\n",
    "\n",
    "        # Pad/trim to max_seq_len\n",
    "        frames = arr\n",
    "        if frames.shape[0] > self.max_seq_len:\n",
    "            start = (frames.shape[0] - self.max_seq_len) // 2\n",
    "            frames = frames[start:start+self.max_seq_len]\n",
    "        elif frames.shape[0] < self.max_seq_len:\n",
    "            pad = np.zeros((self.max_seq_len - frames.shape[0], frames.shape[1]), dtype=frames.dtype)\n",
    "            frames = np.vstack([frames, pad])\n",
    "\n",
    "        if self.normalize and self.mean is not None:\n",
    "            frames = (frames - self.mean) / (self.std + 1e-6)\n",
    "\n",
    "        text = row.get('sentence_text') or row.get('sentence') or \"\"\n",
    "        gloss = row.get('sentence_gloss') or \"\"\n",
    "        full_text = gloss if gloss else text\n",
    "\n",
    "        tokens = self.tokenizer(full_text, return_tensors='pt', truncation=True, padding='max_length', max_length=64)\n",
    "        return {\n",
    "            'frames': torch.tensor(frames, dtype=torch.float32),\n",
    "            'text_input_ids': tokens['input_ids'].squeeze(0),\n",
    "            'text_attention_mask': tokens['attention_mask'].squeeze(0),\n",
    "            'seq_len': torch.tensor(min(arr.shape[0], self.max_seq_len), dtype=torch.long),\n",
    "        }\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    frames = torch.stack([b['frames'] for b in batch])\n",
    "    input_ids = torch.stack([b['text_input_ids'] for b in batch])\n",
    "    attn_mask = torch.stack([b['text_attention_mask'] for b in batch])\n",
    "    seq_len = torch.stack([b['seq_len'] for b in batch])\n",
    "    return frames, input_ids, attn_mask, seq_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711f9845",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrozenTextEncoder(nn.Module):\n",
    "    def __init__(self, model_name=TEXT_MODEL, proj_dim=TEXT_PROJ_DIM):\n",
    "        super().__init__()\n",
    "        self.backbone = AutoModel.from_pretrained(model_name)\n",
    "        for p in self.backbone.parameters():\n",
    "            p.requires_grad = False\n",
    "        hidden = self.backbone.config.hidden_size\n",
    "        self.proj = nn.Linear(hidden, proj_dim)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        with torch.no_grad():\n",
    "            out = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            seq_emb = out.last_hidden_state  # (B, T, H)\n",
    "        return self.proj(seq_emb)           # (B, T, proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2d21df",
   "metadata": {},
   "source": [
    "## Cell 5 â€” Generator (NAT) & Length Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3e7eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LengthPredictor(nn.Module):\n",
    "    def __init__(self, in_dim=TEXT_PROJ_DIM, length_bins=LENGTH_BINS):\n",
    "        super().__init__()\n",
    "        self.length_bins = torch.tensor(length_bins, dtype=torch.float32)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, in_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_dim, len(length_bins))\n",
    "        )\n",
    "\n",
    "    def forward(self, pooled):\n",
    "        logits = self.net(pooled)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class NATBlock(nn.Module):\n",
    "    def __init__(self, dim=HIDDEN_DIM, heads=4, ff_mult=4):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(dim, heads, batch_first=True)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, ff_mult*dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(ff_mult*dim, dim)\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x, context):\n",
    "        # Cross-attend to text context\n",
    "        attn_out, _ = self.attn(x, context, context)\n",
    "        x = self.norm(x + attn_out)\n",
    "        x = x + self.ff(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, pose_dim=POSE_DIM, text_dim=TEXT_PROJ_DIM, latent_dim=LATENT_DIM, hidden_dim=HIDDEN_DIM, layers=NUM_LAYERS):\n",
    "        super().__init__()\n",
    "        self.length_head = LengthPredictor(text_dim)\n",
    "        self.style_proj = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.time_embed = nn.Embedding(MAX_SEQ_LEN, hidden_dim)\n",
    "        self.input_proj = nn.Linear(hidden_dim + text_dim, hidden_dim)\n",
    "        self.blocks = nn.ModuleList([NATBlock(hidden_dim, heads=4) for _ in range(layers)])\n",
    "        self.output = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, pose_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, text_ctx, seq_len=None):\n",
    "        B, T_txt, C = text_ctx.shape\n",
    "        pooled = text_ctx[:, 0]  # use CLS/token 0\n",
    "        len_logits = self.length_head(pooled)\n",
    "\n",
    "        # sample length (teacher-forcing with provided seq_len if available)\n",
    "        if seq_len is not None:\n",
    "            target_len = seq_len\n",
    "        else:\n",
    "            probs = torch.softmax(len_logits, dim=-1)\n",
    "            target_len = torch.multinomial(probs, num_samples=1).squeeze(-1)\n",
    "            target_len = target_len.clamp(0, len(LENGTH_BINS)-1)\n",
    "        target_len_vals = torch.tensor(LENGTH_BINS, device=text_ctx.device)[target_len]\n",
    "        max_len = MAX_SEQ_LEN\n",
    "\n",
    "        # build time queries\n",
    "        z = torch.randn(B, max_len, LATENT_DIM, device=text_ctx.device)\n",
    "        style = self.style_proj(z)\n",
    "        t_idx = torch.arange(max_len, device=text_ctx.device).unsqueeze(0).repeat(B,1)\n",
    "        time_emb = self.time_embed(t_idx)\n",
    "\n",
    "        x = torch.cat([style, time_emb], dim=-1)\n",
    "        # repeat pooled text to concatenate\n",
    "        pooled_rep = pooled.unsqueeze(1).repeat(1, max_len, 1)\n",
    "        x = torch.cat([x, pooled_rep], dim=-1)\n",
    "        x = self.input_proj(x)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x, text_ctx)\n",
    "\n",
    "        poses = self.output(x)\n",
    "        return poses, len_logits, target_len_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fdc2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, pose_dim=POSE_DIM, base=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(pose_dim, base, 3, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(base, base, 3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(base, base*2, 3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(base*2, base*4, 3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "        )\n",
    "        self.head = nn.Linear(base*4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, pose_dim)\n",
    "        x = x.transpose(1, 2)\n",
    "        feat = self.net(x).squeeze(-1)\n",
    "        return self.head(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ae7a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_loss(pred, target, delta=1.0):\n",
    "    return F.smooth_l1_loss(pred, target, beta=delta)\n",
    "\n",
    "\n",
    "def recon_losses(pred, target):\n",
    "    pos = huber_loss(pred, target)\n",
    "    vel = huber_loss(pred[:,1:] - pred[:,:-1], target[:,1:] - target[:,:-1])\n",
    "    acc = huber_loss((pred[:,2:] - pred[:,1:-1]) - (pred[:,1:-1] - pred[:,:-2]), (target[:,2:] - target[:,1:-1]) - (target[:,1:-1] - target[:,:-2]))\n",
    "    return pos + vel + acc\n",
    "\n",
    "\n",
    "def gan_losses(real_logits, fake_logits):\n",
    "    d_loss = F.relu(1.0 - real_logits).mean() + F.relu(1.0 + fake_logits).mean()\n",
    "    g_loss = -fake_logits.mean()\n",
    "    return d_loss, g_loss\n",
    "\n",
    "\n",
    "def bone_length_consistency(poses):\n",
    "    # Simple proxy: variance of pairwise bone lengths (pose coords only x,y,z)\n",
    "    coords = poses.view(poses.shape[0], poses.shape[1], NUM_POSE_LANDMARKS, 4)[...,:3]\n",
    "    # shoulders and hips\n",
    "    ls = torch.norm(coords[:,:,LEFT_SHOULDER] - coords[:,:,RIGHT_SHOULDER], dim=-1)\n",
    "    hs = torch.norm(coords[:,:,LEFT_HIP] - coords[:,:,RIGHT_HIP], dim=-1)\n",
    "    spine = torch.norm(0.5*(coords[:,:,LEFT_SHOULDER]+coords[:,:,RIGHT_SHOULDER]) - 0.5*(coords[:,:,LEFT_HIP]+coords[:,:,RIGHT_HIP]), dim=-1)\n",
    "    stacked = torch.stack([ls, hs, spine], dim=-1)\n",
    "    return stacked.var(dim=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08f8148",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoder = FrozenTextEncoder().to(DEVICE)\n",
    "G = Generator().to(DEVICE)\n",
    "D = Discriminator().to(DEVICE)\n",
    "\n",
    "opt_G = torch.optim.Adam(G.parameters(), lr=LR_G, betas=(BETA1, BETA2))\n",
    "opt_D = torch.optim.Adam(D.parameters(), lr=LR_D, betas=(BETA1, BETA2))\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=DEVICE.type == 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08fe90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ckpt(epoch):\n",
    "    torch.save({\n",
    "        'G': G.state_dict(),\n",
    "        'D': D.state_dict(),\n",
    "        'opt_G': opt_G.state_dict(),\n",
    "        'opt_D': opt_D.state_dict(),\n",
    "        'epoch': epoch,\n",
    "    }, CHECKPOINT_DIR / f\"epoch_{epoch}.pt\")\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    G.train(); D.train()\n",
    "    pbar = tqdm(loader, desc=f\"Epoch {epoch}\")\n",
    "    for frames, input_ids, attn_mask, seq_len in pbar:\n",
    "        frames = frames.to(DEVICE)\n",
    "        input_ids = input_ids.to(DEVICE)\n",
    "        attn_mask = attn_mask.to(DEVICE)\n",
    "        seq_len = seq_len.to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            text_ctx = text_encoder(input_ids, attn_mask)\n",
    "\n",
    "        # --- Train Discriminator ---\n",
    "        opt_D.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            fake, _, _ = G(text_ctx, seq_len)\n",
    "        real_logits = D(frames)\n",
    "        fake_logits = D(fake.detach())\n",
    "        d_loss, _ = gan_losses(real_logits, fake_logits)\n",
    "        d_loss.backward()\n",
    "        nn.utils.clip_grad_norm_(D.parameters(), GRAD_CLIP)\n",
    "        opt_D.step()\n",
    "\n",
    "        # --- Train Generator ---\n",
    "        opt_G.zero_grad()\n",
    "        fake, len_logits, target_len_vals = G(text_ctx, seq_len)\n",
    "        fake_logits = D(fake)\n",
    "        _, g_gan = gan_losses(real_logits=None, fake_logits=fake_logits)  # g part only\n",
    "\n",
    "        rec = recon_losses(fake, frames)\n",
    "        geo = bone_length_consistency(fake)\n",
    "\n",
    "        g_loss = LAMBDA_REC * rec + LAMBDA_ADV * g_gan + LAMBDA_GEO * geo\n",
    "        g_loss.backward()\n",
    "        nn.utils.clip_grad_norm_(G.parameters(), GRAD_CLIP)\n",
    "        opt_G.step()\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            'd_loss': d_loss.item(),\n",
    "            'g_loss': g_loss.item(),\n",
    "            'rec': rec.item(),\n",
    "            'geo': geo.item(),\n",
    "        })\n",
    "\n",
    "    save_ckpt(epoch)\n",
    "    print(f\"ðŸ’¾ Saved checkpoint epoch {epoch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776e839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample(texts, max_len=MAX_SEQ_LEN, checkpoint=None):\n",
    "    if checkpoint:\n",
    "        ckpt = torch.load(checkpoint, map_location=DEVICE)\n",
    "        G.load_state_dict(ckpt['G'])\n",
    "    tokenizer = AutoTokenizer.from_pretrained(TEXT_MODEL)\n",
    "    tokens = tokenizer(texts, return_tensors='pt', padding=True, truncation=True).to(DEVICE)\n",
    "    text_ctx = text_encoder(tokens['input_ids'], tokens['attention_mask'])\n",
    "    fake, _, _ = G(text_ctx)\n",
    "    fake = fake[:, :max_len]\n",
    "    return fake.cpu().numpy()\n",
    "\n",
    "# Example\n",
    "samples = sample([\"Where is the hospital?\", \"I need a doctor\"], checkpoint=None)\n",
    "print(samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f56eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "@torch.no_grad()\n",
    "def visualize_sample(text=\"Where is the hospital?\", checkpoint=None, joint_idx=0):\n",
    "    if checkpoint:\n",
    "        ckpt = torch.load(checkpoint, map_location=DEVICE)\n",
    "        G.load_state_dict(ckpt['G'])\n",
    "    tokens = AutoTokenizer.from_pretrained(TEXT_MODEL)([text], return_tensors='pt', padding=True, truncation=True).to(DEVICE)\n",
    "    text_ctx = text_encoder(tokens['input_ids'], tokens['attention_mask'])\n",
    "    fake, _, _ = G(text_ctx)\n",
    "    fake = fake[0].cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.plot(fake[:, joint_idx], label=f'Joint {joint_idx} (dim 0)')\n",
    "    plt.title(f'Generated trajectory for \"{text}\"')\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_sample()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

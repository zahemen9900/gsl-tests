{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cc7b978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import List\n",
    "\n",
    "BASE_DIR = Path('.').resolve()\n",
    "OUT_DIR = BASE_DIR / 'runs'\n",
    "PROC_META = BASE_DIR / 'proc' / 'processed_metadata.csv'\n",
    "GLOBAL_STATS_PATH = BASE_DIR / 'proc' / 'global_stats.npz'\n",
    "VOCAB_PATH = OUT_DIR / 'tokenizer_vocab.json'\n",
    "\n",
    "INFERENCE_CFG = {\n",
    "    'seq_len': 64,\n",
    "    'input_dim': 540,\n",
    "    'proj_dim': 160,\n",
    "    'embed_dim': 256,\n",
    "    'attn_heads': 4,\n",
    "    'encoder_layers': 4,\n",
    "    'encoder_ff_dim': 512,\n",
    "    'encoder_dropout': 0.1,\n",
    "    'decoder_max_len': 64,\n",
    "    'beam_size': 4,\n",
    "    'beam_length_penalty': 0.8,\n",
    "    'stream_chunk': 4,\n",
    "    'stream_chunk_hop': 4,\n",
    "    'stream_emit_every': 4,\n",
    "    'stream_gate_threshold': 0.12,\n",
    "    'stream_demo_seed': 13,\n",
    "    'stream_demo_sentence_id': None,\n",
    "    'checkpoint_name': 'best_model_top1_0.924.pt'\n",
    "}\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {DEVICE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f044056d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded global stats: (540,)\n"
     ]
    }
   ],
   "source": [
    "def load_global_stats(stats_path: Path) -> tuple[np.ndarray, np.ndarray]:\n",
    "    blob = np.load(stats_path)\n",
    "    return blob['feature_mean'].astype(np.float32), blob['feature_std'].astype(np.float32)\n",
    "\n",
    "def normalize_with_stats(seq: np.ndarray, mean_vec: np.ndarray, std_vec: np.ndarray) -> np.ndarray:\n",
    "    return (seq - mean_vec) / (std_vec + 1e-6)\n",
    "\n",
    "def center_time_crop(seq: np.ndarray, target_len: int) -> np.ndarray:\n",
    "    total = seq.shape[0]\n",
    "    if total <= target_len:\n",
    "        return seq\n",
    "    start = (total - target_len) // 2\n",
    "    return seq[start:start + target_len]\n",
    "\n",
    "def pad_to_length(seq: np.ndarray, target_len: int) -> np.ndarray:\n",
    "    if seq.shape[0] >= target_len:\n",
    "        return seq[:target_len]\n",
    "    pad = np.zeros((target_len - seq.shape[0], seq.shape[1]), dtype=np.float32)\n",
    "    return np.vstack([seq, pad])\n",
    "\n",
    "GLOBAL_MEAN, GLOBAL_STD = load_global_stats(GLOBAL_STATS_PATH)\n",
    "print('Loaded global stats:', GLOBAL_MEAN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68578889",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizer:\n",
    "    \"\"\"Simple word-level tokenizer that mirrors the training notebook.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.token2id = {\n",
    "            '<pad>': 0,\n",
    "            '<sos>': 1,\n",
    "            '<eos>': 2,\n",
    "            '<unk>': 3,\n",
    "        }\n",
    "        self.id2token = {v: k for k, v in self.token2id.items()}\n",
    "        self.vocab_size = len(self.token2id)\n",
    "        self.pad_token_id = self.token2id['<pad>']\n",
    "        self.sos_token_id = self.token2id['<sos>']\n",
    "        self.eos_token_id = self.token2id['<eos>']\n",
    "        self.unk_token_id = self.token2id['<unk>']\n",
    "\n",
    "    def _tokenize(self, text: str) -> list[str]:\n",
    "        text = text.lower()\n",
    "        for char in [',', '.', '?', '!', '\"', \"'\"]:\n",
    "            text = text.replace(char, '')\n",
    "        return text.split()\n",
    "\n",
    "    def encode(self, text: str, add_special_tokens: bool = True) -> List[int]:\n",
    "        ids = [self.token2id.get(tok, self.unk_token_id) for tok in self._tokenize(text)]\n",
    "        if add_special_tokens:\n",
    "            ids = [self.sos_token_id] + ids + [self.eos_token_id]\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids: List[int], skip_special_tokens: bool = True) -> str:\n",
    "        tokens = []\n",
    "        for idx in ids:\n",
    "            token = self.id2token.get(int(idx), '<unk>')\n",
    "            if skip_special_tokens and token in {'<pad>', '<sos>', '<eos>'}:\n",
    "                continue\n",
    "            tokens.append(token)\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    @classmethod\n",
    "    def from_vocab_file(cls, vocab_path: Path):\n",
    "        tokenizer = cls()\n",
    "        if not vocab_path.exists():\n",
    "            print(f\"‚ö†Ô∏è  Vocab file not found at {vocab_path}; using fallback tokens.\")\n",
    "            return tokenizer\n",
    "        with open(vocab_path, 'r', encoding='utf-8') as handle:\n",
    "            blob = json.load(handle)\n",
    "        token_map = blob.get('token2id', blob)\n",
    "        tokenizer.token2id = {token: int(idx) for token, idx in token_map.items()}\n",
    "        tokenizer.id2token = {idx: token for token, idx in tokenizer.token2id.items()}\n",
    "        tokenizer.vocab_size = len(tokenizer.token2id)\n",
    "        tokenizer.pad_token_id = tokenizer.token2id.get('<pad>', tokenizer.pad_token_id)\n",
    "        tokenizer.sos_token_id = tokenizer.token2id.get('<sos>', tokenizer.sos_token_id)\n",
    "        tokenizer.eos_token_id = tokenizer.token2id.get('<eos>', tokenizer.eos_token_id)\n",
    "        tokenizer.unk_token_id = tokenizer.token2id.get('<unk>', tokenizer.unk_token_id)\n",
    "        print(f\"Loaded tokenizer vocab: {tokenizer.vocab_size} tokens\")\n",
    "        return tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81c80807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenizer vocab: 4249 tokens\n",
      "Loaded metadata: 1482 clips\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizer.from_vocab_file(VOCAB_PATH)\n",
    "\n",
    "if PROC_META.exists():\n",
    "    inference_meta = pd.read_csv(PROC_META)\n",
    "    print(f\"Loaded metadata: {len(inference_meta)} clips\")\n",
    "else:\n",
    "    inference_meta = pd.DataFrame()\n",
    "    print(f\"‚ö†Ô∏è  Metadata file missing: {PROC_META}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c667c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameProjector(nn.Module):\n",
    "    def __init__(self, in_dim, proj_dim=160):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(in_dim)\n",
    "        self.fc1 = nn.Linear(in_dim, proj_dim)\n",
    "        self.fc2 = nn.Linear(proj_dim, proj_dim)\n",
    "        self.act = nn.GELU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.norm(x)\n",
    "        out = self.act(self.fc1(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.act(self.fc2(out))\n",
    "        return out\n",
    "\n",
    "\n",
    "class TemporalPositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=512):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        length = x.size(1)\n",
    "        return self.dropout(x + self.pe[:, :length])\n",
    "\n",
    "\n",
    "class TemporalTransformerEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim,\n",
    "        embed_dim=256,\n",
    "        n_layers=4,\n",
    "        attn_heads=4,\n",
    "        ff_dim=512,\n",
    "        dropout=0.1,\n",
    "        max_len=256\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(in_dim, embed_dim)\n",
    "        self.pos_encoder = TemporalPositionalEncoding(embed_dim, dropout=dropout, max_len=max_len)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=attn_heads,\n",
    "            dim_feedforward=ff_dim,\n",
    "            dropout=dropout,\n",
    "            activation='gelu',\n",
    "            batch_first=True,\n",
    "            norm_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x, key_padding_mask=None, return_sequence=False):\n",
    "        seq = self.input_proj(x)\n",
    "        seq = self.pos_encoder(seq)\n",
    "        seq = self.encoder(seq, src_key_padding_mask=key_padding_mask)\n",
    "        pooled = torch.mean(seq, dim=1)\n",
    "        pooled = nn.functional.normalize(self.norm(pooled), dim=-1)\n",
    "        attn_proxy = torch.ones(x.size(0), x.size(1), device=x.device)\n",
    "        if return_sequence:\n",
    "            return pooled, attn_proxy, seq\n",
    "        return pooled, attn_proxy\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[: x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class SignTranslationModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        vocab_size,\n",
    "        proj_dim=160,\n",
    "        embed_dim=256,\n",
    "        attn_heads=4,\n",
    "        encoder_layers=4,\n",
    "        encoder_ff_dim=512,\n",
    "        encoder_dropout=0.1,\n",
    "        max_seq_len=64\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.projector = FrameProjector(input_dim, proj_dim)\n",
    "        self.encoder = TemporalTransformerEncoder(\n",
    "            proj_dim,\n",
    "            embed_dim=embed_dim,\n",
    "            n_layers=encoder_layers,\n",
    "            attn_heads=attn_heads,\n",
    "            ff_dim=encoder_ff_dim,\n",
    "            dropout=encoder_dropout,\n",
    "            max_len=max_seq_len\n",
    "        )\n",
    "        self.tgt_embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_encoder = PositionalEncoding(embed_dim)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=attn_heads,\n",
    "            dim_feedforward=embed_dim * 4,\n",
    "            dropout=0.1,\n",
    "            activation='gelu'\n",
    "        )\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=2)\n",
    "        self.generator = nn.Linear(embed_dim, vocab_size)\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.mask_token = nn.Parameter(torch.zeros(1, 1, proj_dim))\n",
    "        self.mask_decoder = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_dim, proj_dim)\n",
    "        )\n",
    "\n",
    "    def encode_visual(self, x):\n",
    "        proj = self.projector(x)\n",
    "        embedding, _ = self.encoder(proj)\n",
    "        return embedding\n",
    "\n",
    "    def encode_for_inference(self, x):\n",
    "        proj = self.projector(x)\n",
    "        embedding, attn_weights, context = self.encoder(proj, return_sequence=True)\n",
    "        return embedding, proj, attn_weights\n",
    "\n",
    "    def forward(self, src, tgt, tgt_mask=None, tgt_pad_mask=None):\n",
    "        proj = self.projector(src)\n",
    "        embedding, _, context = self.encoder(proj, return_sequence=True)\n",
    "        memory = context.permute(1, 0, 2)\n",
    "        tgt_emb = self.tgt_embed(tgt).permute(1, 0, 2)\n",
    "        tgt_emb = self.pos_encoder(tgt_emb)\n",
    "        output = self.decoder(\n",
    "            tgt_emb,\n",
    "            memory,\n",
    "            tgt_mask=tgt_mask,\n",
    "            tgt_key_padding_mask=tgt_pad_mask\n",
    "        )\n",
    "        logits = self.generator(output.permute(1, 0, 2))\n",
    "        return logits, embedding\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def project_frames(self, x):\n",
    "        return self.projector(x)\n",
    "\n",
    "    def masked_frame_loss(self, src, mask_ratio=0.15):\n",
    "        proj = self.projector(src)\n",
    "        bsz, seq_len, _ = proj.shape\n",
    "        mask = (torch.rand(bsz, seq_len, device=proj.device) < mask_ratio)\n",
    "        if not mask.any():\n",
    "            rand_b = torch.randint(0, bsz, (1,), device=proj.device)\n",
    "            rand_t = torch.randint(0, seq_len, (1,), device=proj.device)\n",
    "            mask[rand_b, rand_t] = True\n",
    "        masked_proj = proj.clone()\n",
    "        masked_proj[mask] = self.mask_token.expand_as(proj)[mask]\n",
    "        _, _, context = self.encoder(masked_proj, return_sequence=True)\n",
    "        recon = self.mask_decoder(context)\n",
    "        loss = nn.functional.smooth_l1_loss(recon[mask], proj[mask])\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89bcdf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zahemen/miniconda3/envs/signtalk_env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint: best_model_top1_0.924.pt\n"
     ]
    }
   ],
   "source": [
    "def build_seq2seq_model(cfg: dict, tokenizer: SimpleTokenizer) -> SignTranslationModel:\n",
    "    return SignTranslationModel(\n",
    "        input_dim=cfg['input_dim'],\n",
    "        vocab_size=tokenizer.vocab_size,\n",
    "        proj_dim=cfg['proj_dim'],\n",
    "        embed_dim=cfg['embed_dim'],\n",
    "        attn_heads=cfg['attn_heads'],\n",
    "        encoder_layers=cfg['encoder_layers'],\n",
    "        encoder_ff_dim=cfg['encoder_ff_dim'],\n",
    "        encoder_dropout=cfg['encoder_dropout'],\n",
    "        max_seq_len=cfg['seq_len']\n",
    "    )\n",
    "\n",
    "\n",
    "def load_seq2seq_checkpoint(checkpoint_name: str | None) -> SignTranslationModel:\n",
    "    if not checkpoint_name:\n",
    "        raise ValueError('INFERENCE_CFG[\"checkpoint_name\"] must be set to a .pt file produced by training.')\n",
    "    ckpt_path = OUT_DIR / checkpoint_name\n",
    "    if not ckpt_path.exists():\n",
    "        raise FileNotFoundError(f'Checkpoint not found: {ckpt_path}')\n",
    "\n",
    "    model = build_seq2seq_model(INFERENCE_CFG, tokenizer).to(DEVICE)\n",
    "    state = torch.load(ckpt_path, map_location=DEVICE)\n",
    "    missing, unexpected = model.load_state_dict(state, strict=False)\n",
    "    if missing:\n",
    "        print(f'‚ö†Ô∏è  Missing keys: {missing}')\n",
    "    if unexpected:\n",
    "        print(f'‚ö†Ô∏è  Unexpected keys: {unexpected}')\n",
    "    model.eval()\n",
    "    print(f'Loaded checkpoint: {ckpt_path.name}')\n",
    "    return model\n",
    "\n",
    "\n",
    "seq2seq_model = load_seq2seq_checkpoint(INFERENCE_CFG.get('checkpoint_name'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44ac21cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz: int) -> torch.Tensor:\n",
    "    mask = torch.triu(torch.ones(sz, sz)) == 1\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def _length_penalty(length: int, alpha: float) -> float:\n",
    "    if alpha <= 0:\n",
    "        return 1.0\n",
    "    return ((5 + length) / 6) ** alpha\n",
    "\n",
    "\n",
    "def _strip_special_tokens(seq: List[int], tokenizer) -> List[int]:\n",
    "    cleaned: List[int] = []\n",
    "    for tid in seq:\n",
    "        if tid == tokenizer.sos_token_id:\n",
    "            continue\n",
    "        if tid == tokenizer.eos_token_id:\n",
    "            break\n",
    "        cleaned.append(tid)\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def _beam_search_single(\n",
    "    model,\n",
    "    memory: torch.Tensor,\n",
    "    tokenizer,\n",
    "    device,\n",
    "    max_len: int,\n",
    "    beam_size: int,\n",
    "    length_penalty: float\n",
    ") -> List[int]:\n",
    "    bos = tokenizer.sos_token_id\n",
    "    eos = tokenizer.eos_token_id\n",
    "    beams = [(0.0, [bos], False)]\n",
    "    finished: List[tuple[float, List[int]]] = []\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        new_beams = []\n",
    "        for logprob, seq, done in beams:\n",
    "            if done:\n",
    "                new_beams.append((logprob, seq, True))\n",
    "                continue\n",
    "            tgt = torch.tensor(seq, dtype=torch.long, device=device).unsqueeze(0)\n",
    "            tgt_mask = generate_square_subsequent_mask(tgt.size(1)).to(device)\n",
    "            tgt_emb = model.tgt_embed(tgt).permute(1, 0, 2)\n",
    "            tgt_emb = model.pos_encoder(tgt_emb)\n",
    "            decoder_out = model.decoder(tgt_emb, memory, tgt_mask=tgt_mask)\n",
    "            logits = model.generator(decoder_out[-1])\n",
    "            log_probs = torch.log_softmax(logits.squeeze(0), dim=-1)\n",
    "            topk = torch.topk(log_probs, k=min(beam_size, log_probs.size(-1)))\n",
    "            for value, index in zip(topk.values.tolist(), topk.indices.tolist()):\n",
    "                next_seq = seq + [int(index)]\n",
    "                next_done = int(index) == eos\n",
    "                next_logprob = logprob + float(value)\n",
    "                new_beams.append((next_logprob, next_seq, next_done))\n",
    "                if next_done:\n",
    "                    finished.append((next_logprob, next_seq))\n",
    "        if not new_beams:\n",
    "            break\n",
    "        new_beams.sort(key=lambda x: x[0], reverse=True)\n",
    "        beams = new_beams[:beam_size]\n",
    "        if all(done for _, _, done in beams):\n",
    "            break\n",
    "\n",
    "    def _select(candidates: List[tuple[float, List[int]]]) -> List[int]:\n",
    "        scored = [\n",
    "            (score / _length_penalty(len(seq), length_penalty), seq)\n",
    "            for score, seq in candidates\n",
    "        ]\n",
    "        return max(scored, key=lambda x: x[0])[1]\n",
    "\n",
    "    if finished:\n",
    "        return _select(finished)\n",
    "    return _select([(score, seq) for score, seq, _ in beams])\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def beam_search_decode_batch(\n",
    "    model,\n",
    "    src_batch: torch.Tensor,\n",
    "    tokenizer,\n",
    "    max_len: int = 64,\n",
    "    beam_size: int = 4,\n",
    "    length_penalty: float = 0.8\n",
    ") -> List[List[int]]:\n",
    "    model.eval()\n",
    "    beam_size = max(1, beam_size)\n",
    "    device = src_batch.device\n",
    "    proj = model.projector(src_batch)\n",
    "    _, _, context = model.encoder(proj, return_sequence=True)\n",
    "    memory = context.permute(1, 0, 2)\n",
    "    decoded: List[List[int]] = []\n",
    "    for idx in range(src_batch.size(0)):\n",
    "        sample_memory = memory[:, idx:idx + 1, :]\n",
    "        best_seq = _beam_search_single(\n",
    "            model,\n",
    "            sample_memory,\n",
    "            tokenizer,\n",
    "            device,\n",
    "            max_len=max_len,\n",
    "            beam_size=beam_size,\n",
    "            length_penalty=length_penalty\n",
    "        )\n",
    "        decoded.append(_strip_special_tokens(best_seq, tokenizer))\n",
    "    return decoded\n",
    "\n",
    "\n",
    "def ids_to_sentence(token_ids, tokenizer):\n",
    "    if isinstance(token_ids, torch.Tensor):\n",
    "        ids = token_ids.tolist()\n",
    "    else:\n",
    "        ids = list(token_ids)\n",
    "    cleaned = []\n",
    "    for tid in ids:\n",
    "        if tid == tokenizer.eos_token_id:\n",
    "            break\n",
    "        if tid == tokenizer.pad_token_id:\n",
    "            continue\n",
    "        cleaned.append(tid)\n",
    "    return tokenizer.decode(cleaned, skip_special_tokens=True).strip()\n",
    "\n",
    "\n",
    "def word_error_rate(reference: str, hypothesis: str) -> float:\n",
    "    ref_words = reference.strip().split()\n",
    "    hyp_words = hypothesis.strip().split()\n",
    "    if not ref_words and not hyp_words:\n",
    "        return 0.0\n",
    "    if not ref_words:\n",
    "        return float(len(hyp_words) > 0)\n",
    "    dp = np.zeros((len(ref_words) + 1, len(hyp_words) + 1), dtype=np.int32)\n",
    "    for i in range(len(ref_words) + 1):\n",
    "        dp[i, 0] = i\n",
    "    for j in range(len(hyp_words) + 1):\n",
    "        dp[0, j] = j\n",
    "    for i in range(1, len(ref_words) + 1):\n",
    "        for j in range(1, len(hyp_words) + 1):\n",
    "            cost = 0 if ref_words[i - 1] == hyp_words[j - 1] else 1\n",
    "            dp[i, j] = min(\n",
    "                dp[i - 1, j] + 1,\n",
    "                dp[i, j - 1] + 1,\n",
    "                dp[i - 1, j - 1] + cost\n",
    "            )\n",
    "    return dp[len(ref_words), len(hyp_words)] / max(len(ref_words), 1)\n",
    "\n",
    "\n",
    "def simple_bleu_score(reference: str, hypothesis: str, max_n: int = 4) -> float:\n",
    "    ref_tokens = reference.strip().split()\n",
    "    hyp_tokens = hypothesis.strip().split()\n",
    "    if not ref_tokens and not hyp_tokens:\n",
    "        return 1.0\n",
    "    if not hyp_tokens:\n",
    "        return 0.0\n",
    "    precisions = []\n",
    "    eps = 1e-9\n",
    "    for n in range(1, max_n + 1):\n",
    "        if len(hyp_tokens) < n:\n",
    "            precisions.append(eps)\n",
    "            continue\n",
    "        ref_range = max(len(ref_tokens) - n + 1, 0)\n",
    "        ref_counts = Counter(tuple(ref_tokens[i:i + n]) for i in range(ref_range))\n",
    "        hyp_counts = Counter(tuple(hyp_tokens[i:i + n]) for i in range(len(hyp_tokens) - n + 1))\n",
    "        overlap = sum(min(count, ref_counts.get(gram, 0)) for gram, count in hyp_counts.items())\n",
    "        total = sum(hyp_counts.values())\n",
    "        precisions.append((overlap + eps) / (total + eps))\n",
    "    log_precision = sum(math.log(p) for p in precisions) / len(precisions)\n",
    "    ref_len = len(ref_tokens)\n",
    "    hyp_len = len(hyp_tokens)\n",
    "    bp = 1.0 if hyp_len > ref_len else math.exp(1 - (ref_len / max(hyp_len, 1)))\n",
    "    return float(bp * math.exp(log_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d49bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_feature_sequence(path: str | Path) -> np.ndarray:\n",
    "    arr = np.load(path).astype(np.float32)\n",
    "    if arr.ndim != 2 or arr.shape[1] != INFERENCE_CFG['input_dim']:\n",
    "        raise ValueError(f'Unexpected feature shape: {arr.shape}')\n",
    "    return arr\n",
    "\n",
    "\n",
    "def preprocess_feature(path: str | Path) -> np.ndarray:\n",
    "    seq = load_feature_sequence(path)\n",
    "    if seq.shape[0] > INFERENCE_CFG['seq_len']:\n",
    "        seq = center_time_crop(seq, INFERENCE_CFG['seq_len'])\n",
    "    seq = normalize_with_stats(seq, GLOBAL_MEAN, GLOBAL_STD)\n",
    "    seq = pad_to_length(seq, INFERENCE_CFG['seq_len'])\n",
    "    return seq.astype(np.float32)\n",
    "\n",
    "\n",
    "def run_decoder_inference(\n",
    "    model,\n",
    "    feature_path: str | Path,\n",
    "    reference_text: str | None = None,\n",
    "    max_len: int | None = None,\n",
    "    beam_size: int | None = None,\n",
    "    length_penalty: float | None = None\n",
    "):\n",
    "    seq = preprocess_feature(feature_path)\n",
    "    batch = torch.from_numpy(seq).unsqueeze(0).to(DEVICE)\n",
    "    decoded = beam_search_decode_batch(\n",
    "        model,\n",
    "        batch,\n",
    "        tokenizer,\n",
    "        max_len=max_len or INFERENCE_CFG['decoder_max_len'],\n",
    "        beam_size=beam_size or INFERENCE_CFG.get('beam_size', 1),\n",
    "        length_penalty=length_penalty if length_penalty is not None else INFERENCE_CFG.get('beam_length_penalty', 0.0)\n",
    "    )\n",
    "    prediction = ids_to_sentence(decoded[0], tokenizer)\n",
    "    metrics = {}\n",
    "    if reference_text:\n",
    "        metrics['wer'] = word_error_rate(reference_text, prediction)\n",
    "        metrics['bleu'] = simple_bleu_score(reference_text, prediction)\n",
    "    return {'prediction': prediction, 'metrics': metrics}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "093cd5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_feature_sequence(path: str | Path) -> np.ndarray:\n",
    "    arr = np.load(path).astype(np.float32)\n",
    "    if arr.ndim != 2 or arr.shape[1] != INFERENCE_CFG['input_dim']:\n",
    "        raise ValueError(f'Unexpected feature shape: {arr.shape}')\n",
    "    return arr\n",
    "\n",
    "\n",
    "def preprocess_feature(path: str | Path) -> np.ndarray:\n",
    "    seq = load_feature_sequence(path)\n",
    "    if seq.shape[0] > INFERENCE_CFG['seq_len']:\n",
    "        seq = center_time_crop(seq, INFERENCE_CFG['seq_len'])\n",
    "    seq = normalize_with_stats(seq, GLOBAL_MEAN, GLOBAL_STD)\n",
    "    seq = pad_to_length(seq, INFERENCE_CFG['seq_len'])\n",
    "    return seq.astype(np.float32)\n",
    "\n",
    "\n",
    "def run_decoder_inference(\n",
    "    model,\n",
    "    feature_path: str | Path,\n",
    "    reference_text: str | None = None,\n",
    "    max_len: int | None = None,\n",
    "    beam_size: int | None = None,\n",
    "    length_penalty: float | None = None\n",
    "):\n",
    "    seq = preprocess_feature(feature_path)\n",
    "    batch = torch.from_numpy(seq).unsqueeze(0).to(DEVICE)\n",
    "    decoded = beam_search_decode_batch(\n",
    "        model,\n",
    "        batch,\n",
    "        tokenizer,\n",
    "        max_len=max_len or INFERENCE_CFG['decoder_max_len'],\n",
    "        beam_size=beam_size or INFERENCE_CFG.get('beam_size', 1),\n",
    "        length_penalty=length_penalty if length_penalty is not None else INFERENCE_CFG.get('beam_length_penalty', 0.0)\n",
    "    )\n",
    "    prediction = ids_to_sentence(decoded[0], tokenizer)\n",
    "    metrics = {}\n",
    "    if reference_text:\n",
    "        metrics['wer'] = word_error_rate(reference_text, prediction)\n",
    "        metrics['bleu'] = simple_bleu_score(reference_text, prediction)\n",
    "    return {'prediction': prediction, 'metrics': metrics}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0c9031",
   "metadata": {},
   "source": [
    "### Streaming inference helpers\n",
    "The next cells build a light-weight streaming buffer and motion gate so we can mimic live pose ingest before dispatching tokens to the decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75fb14d",
   "metadata": {},
   "source": [
    "### Simulate streaming inference\n",
    "Select a sample clip from the processed metadata, push its pose packets through the streaming buffer, and capture gate energy for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acd02eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_stream_sample(meta: pd.DataFrame, cfg: dict) -> pd.Series:\n",
    "    if meta.empty:\n",
    "        raise RuntimeError('Metadata is empty; run the preprocessing/export pipeline first.')\n",
    "    target_sid = cfg.get('stream_demo_sentence_id')\n",
    "    pool = meta\n",
    "    if target_sid is not None:\n",
    "        filtered = meta[meta['sentence_id'] == target_sid]\n",
    "        if not filtered.empty:\n",
    "            pool = filtered\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  No samples found for sentence_id={target_sid}; sampling from full set instead.\")\n",
    "    seed = int(cfg.get('stream_demo_seed', 0))\n",
    "    return pool.sample(1, random_state=seed).iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2c5fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RollingFeatureBuffer:\n",
    "    \"\"\"Maintain a fixed-length sliding window of pose frames for streaming.\"\"\"\n",
    "\n",
    "    def __init__(self, feature_dim: int, max_len: int):\n",
    "        self.feature_dim = feature_dim\n",
    "        self.max_len = max_len\n",
    "        self.frames: list[np.ndarray] = []\n",
    "\n",
    "    def append(self, frame: np.ndarray) -> np.ndarray:\n",
    "        if frame.shape[-1] != self.feature_dim:\n",
    "            raise ValueError(f'Expected feature dim {self.feature_dim}, got {frame.shape[-1]}')\n",
    "        self.frames.append(frame.astype(np.float32))\n",
    "        if len(self.frames) > self.max_len:\n",
    "            self.frames = self.frames[-self.max_len:]\n",
    "        return self.to_array()\n",
    "\n",
    "    def to_array(self) -> np.ndarray:\n",
    "        if not self.frames:\n",
    "            return np.zeros((self.max_len, self.feature_dim), dtype=np.float32)\n",
    "        seq = np.stack(self.frames, axis=0)\n",
    "        if seq.shape[0] < self.max_len:\n",
    "            pad = np.zeros((self.max_len - seq.shape[0], self.feature_dim), dtype=np.float32)\n",
    "            seq = np.vstack([pad, seq])\n",
    "        return seq\n",
    "\n",
    "    def reset(self):\n",
    "        self.frames.clear()\n",
    "\n",
    "\n",
    "class MotionEnergyGate:\n",
    "    \"\"\"Simple gate that fires when motion energy exceeds a rolling threshold.\"\"\"\n",
    "\n",
    "    def __init__(self, window: int = 8, threshold: float = 0.15):\n",
    "        self.window = window\n",
    "        self.threshold = threshold\n",
    "        self.energy_history: list[float] = []\n",
    "\n",
    "    def update(self, frame_seq: np.ndarray) -> bool:\n",
    "        if frame_seq.shape[0] < 2:\n",
    "            return False\n",
    "        diffs = np.linalg.norm(frame_seq[1:] - frame_seq[:-1], axis=-1)\n",
    "        energy = float(np.mean(diffs[-self.window:]))\n",
    "        self.energy_history.append(energy)\n",
    "        if len(self.energy_history) > 100:\n",
    "            self.energy_history = self.energy_history[-100:]\n",
    "        adaptive_thresh = max(self.threshold, np.mean(self.energy_history[-self.window:]) * 0.8)\n",
    "        return energy > adaptive_thresh\n",
    "\n",
    "    def reset(self):\n",
    "        self.energy_history.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c3b69ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_feature_chunks(feature_path: str | Path, chunk_size: int = 4):\n",
    "    \"\"\"Yield small frame batches to mimic packets arriving from a pose detector.\"\"\"\n",
    "    seq = load_feature_sequence(feature_path)\n",
    "    for idx in range(0, seq.shape[0], chunk_size):\n",
    "        yield seq[idx: idx + chunk_size]\n",
    "\n",
    "\n",
    "def normalize_stream_chunk(chunk: np.ndarray) -> np.ndarray:\n",
    "    chunk = normalize_with_stats(chunk, GLOBAL_MEAN, GLOBAL_STD)\n",
    "    return chunk.astype(np.float32)\n",
    "\n",
    "\n",
    "def simulate_stream(sample_meta_row: pd.Series, chunk_size: int = 4):\n",
    "    \"\"\"Generator that yields (frames, metadata) packets for visualization/inference.\"\"\"\n",
    "    feature_path = Path(sample_meta_row['feature_path'])\n",
    "    for packet in stream_feature_chunks(feature_path, chunk_size=chunk_size):\n",
    "        yield {\n",
    "            'frames': normalize_stream_chunk(packet),\n",
    "            'video': sample_meta_row.get('video_file', 'n/a'),\n",
    "            'sentence': sample_meta_row.get('sentence', '')\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a97ea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def run_streaming_inference(\n",
    "    model: SignTranslationModel,\n",
    "    stream_packets,\n",
    "    tokenizer: SimpleTokenizer,\n",
    "    chunk_hop: int = 4,\n",
    "    emit_every: int = 4,\n",
    "    gate_threshold: float = 0.12,\n",
    "    max_tokens: int | None = None,\n",
    "    beam_size: int | None = None,\n",
    "    length_penalty: float | None = None\n",
    "):\n",
    "    buffer = RollingFeatureBuffer(feature_dim=INFERENCE_CFG['input_dim'], max_len=INFERENCE_CFG['seq_len'])\n",
    "    gate = MotionEnergyGate(window=emit_every, threshold=gate_threshold)\n",
    "    decoded_tokens: List[int] = []\n",
    "    intermediate_predictions = []\n",
    "    beam = beam_size or INFERENCE_CFG.get('beam_size', 1)\n",
    "    penalty = length_penalty if length_penalty is not None else INFERENCE_CFG.get('beam_length_penalty', 0.0)\n",
    "\n",
    "    for step, packet in enumerate(stream_packets):\n",
    "        frames = packet['frames']\n",
    "        for i in range(0, len(frames), chunk_hop):\n",
    "            chunk = frames[i:i + chunk_hop]\n",
    "            if chunk.size == 0:\n",
    "                continue\n",
    "            for frame in chunk:\n",
    "                seq = buffer.append(frame)\n",
    "                gate_ready = gate.update(seq[-chunk_hop:])\n",
    "                should_emit = (step + 1) % emit_every == 0 or gate_ready\n",
    "                if not should_emit:\n",
    "                    continue\n",
    "                prep = pad_to_length(seq, INFERENCE_CFG['seq_len']).astype(np.float32)\n",
    "                batch = torch.from_numpy(prep).unsqueeze(0).to(DEVICE)\n",
    "                decoded = beam_search_decode_batch(\n",
    "                    model,\n",
    "                    batch,\n",
    "                    tokenizer,\n",
    "                    max_len=max_tokens or INFERENCE_CFG['decoder_max_len'],\n",
    "                    beam_size=beam,\n",
    "                    length_penalty=penalty\n",
    "                )\n",
    "                sentence = ids_to_sentence(decoded[0], tokenizer)\n",
    "                intermediate_predictions.append(sentence)\n",
    "                if sentence:\n",
    "                    decoded_tokens = tokenizer.encode(sentence, add_special_tokens=False)\n",
    "                if max_tokens and len(decoded_tokens) >= max_tokens:\n",
    "                    break\n",
    "            if max_tokens and len(decoded_tokens) >= max_tokens:\n",
    "                break\n",
    "        if max_tokens and len(decoded_tokens) >= max_tokens:\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        'final_transcript': intermediate_predictions[-1] if intermediate_predictions else '',\n",
    "        'all_hypotheses': intermediate_predictions,\n",
    "        'gate_history': gate.energy_history\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d03d46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ Streaming sample:\n",
      "   Video: 1845E.mp4\n",
      "   Sentence: I'll help you with your balance exercises to improve stability.\n",
      "   Packets: 65 (chunk=4)\n",
      "üó£Ô∏è  Final transcript: your legs\n",
      "   Hypotheses emitted: 228\n",
      "   Gate samples captured: 100\n"
     ]
    }
   ],
   "source": [
    "stream_sample = choose_stream_sample(inference_meta, INFERENCE_CFG)\n",
    "stream_packets = list(simulate_stream(stream_sample, chunk_size=INFERENCE_CFG['stream_chunk']))\n",
    "stream_result = run_streaming_inference(\n",
    "    seq2seq_model,\n",
    "    stream_packets,\n",
    "    tokenizer,\n",
    "    chunk_hop=INFERENCE_CFG['stream_chunk_hop'],\n",
    "    emit_every=INFERENCE_CFG['stream_emit_every'],\n",
    "    gate_threshold=INFERENCE_CFG['stream_gate_threshold'],\n",
    "    max_tokens=INFERENCE_CFG['decoder_max_len'],\n",
    "    beam_size=INFERENCE_CFG.get('beam_size'),\n",
    "    length_penalty=INFERENCE_CFG.get('beam_length_penalty')\n",
    ")\n",
    "\n",
    "print('üé¨ Streaming sample:')\n",
    "print(f\"   Video: {stream_sample.get('video_file', 'n/a')}\")\n",
    "print(f\"   Sentence: {stream_sample.get('sentence', '').strip()}\")\n",
    "print(f\"   Packets: {len(stream_packets)} (chunk={INFERENCE_CFG['stream_chunk']})\")\n",
    "print(f\"üó£Ô∏è  Final transcript: {stream_result['final_transcript']}\")\n",
    "print(f\"   Hypotheses emitted: {len(stream_result['all_hypotheses'])}\")\n",
    "print(f\"   Gate samples captured: {len(stream_result.get('gate_history', []))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1ae2354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_live_camera(model: SignTranslationModel, tokenizer: SimpleTokenizer):\n",
    "    if cv2 is None:\n",
    "        print('cv2 missing; skipping live decode.')\n",
    "        return\n",
    "    try:\n",
    "        seq = capture_webcam_stream()\n",
    "    except RuntimeError as exc:\n",
    "        print('Live capture failed:', exc)\n",
    "        return\n",
    "    padded = pad_to_length(seq, INFERENCE_CFG['seq_len'])\n",
    "    batch = torch.from_numpy(padded).unsqueeze(0).to(DEVICE)\n",
    "    decoded = beam_search_decode_batch(\n",
    "        model,\n",
    "        batch,\n",
    "        tokenizer,\n",
    "        max_len=INFERENCE_CFG['decoder_max_len'],\n",
    "        beam_size=INFERENCE_CFG.get('beam_size', 1),\n",
    "        length_penalty=INFERENCE_CFG.get('beam_length_penalty', 0.0)\n",
    "    )\n",
    "    print('Live prediction:', ids_to_sentence(decoded[0], tokenizer))\n",
    "\n",
    "# decode_live_camera(seq2seq_model, tokenizer)  # Uncomment when pose extraction is wired up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eadf32",
   "metadata": {},
   "source": [
    "### Visualizing gate energy\n",
    "Plot the motion energy history captured by the gate to reason about latency/trigger points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "506db2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if 'stream_result' not in globals():\n",
    "    raise RuntimeError('No streaming results available; run the \"Simulate streaming inference\" cell first.')\n",
    "\n",
    "energy = stream_result.get('gate_history', [])\n",
    "if not energy:\n",
    "    raise RuntimeError('Gate history empty; ensure the stream produced enough frames.')\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.plot(energy, label='motion energy')\n",
    "plt.axhline(y=np.mean(energy), color='orange', linestyle='--', label='mean energy')\n",
    "plt.title('Motion gate energy over time')\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('energy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74718ec0",
   "metadata": {},
   "source": [
    "### Webcam / live capture stub\n",
    "Below is a helper for testing with OpenCV if MediaPipe and a camera are available. It degrades gracefully when dependencies are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e0eb0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import cv2  # type: ignore\n",
    "except Exception as exc:  # pragma: no cover\n",
    "    cv2 = None\n",
    "    print('OpenCV not available:', exc)\n",
    "\n",
    "\n",
    "def capture_webcam_stream(max_frames: int = 256, downsample: int = 2):\n",
    "    \"\"\"Yield normalized pose vectors from MediaPipe/OpenCV; returns empty if unavailable.\"\"\"\n",
    "    if cv2 is None:\n",
    "        raise RuntimeError('cv2 is not installed in this environment.')\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        cap.release()\n",
    "        raise RuntimeError('Could not open webcam.')\n",
    "\n",
    "    collected = []\n",
    "    try:\n",
    "        frame_idx = 0\n",
    "        while frame_idx < max_frames:\n",
    "            ok, frame = cap.read()\n",
    "            if not ok:\n",
    "                break\n",
    "            if frame_idx % downsample == 0:\n",
    "                # Placeholder: integrate MediaPipe pose extraction here.\n",
    "                pose_vec = np.zeros(INFERENCE_CFG['input_dim'], dtype=np.float32)\n",
    "                collected.append(pose_vec)\n",
    "            frame_idx += 1\n",
    "    finally:\n",
    "        cap.release()\n",
    "    if not collected:\n",
    "        raise RuntimeError('No frames collected; ensure MediaPipe integration fills pose_vec.')\n",
    "    seq = np.stack(collected, axis=0)\n",
    "    seq = normalize_with_stats(seq, GLOBAL_MEAN, GLOBAL_STD)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00379b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_live_camera(model: SignTranslationModel, tokenizer: SimpleTokenizer):\n",
    "    if cv2 is None:\n",
    "        print('cv2 missing; skipping live decode.')\n",
    "        return\n",
    "    try:\n",
    "        seq = capture_webcam_stream()\n",
    "    except RuntimeError as exc:\n",
    "        print('Live capture failed:', exc)\n",
    "        return\n",
    "    padded = pad_to_length(seq, INFERENCE_CFG['seq_len'])\n",
    "    batch = torch.from_numpy(padded).unsqueeze(0).to(DEVICE)\n",
    "    decoded = beam_search_decode_batch(\n",
    "        model,\n",
    "        batch,\n",
    "        tokenizer,\n",
    "        max_len=INFERENCE_CFG['decoder_max_len'],\n",
    "        beam_size=INFERENCE_CFG.get('beam_size', 1),\n",
    "        length_penalty=INFERENCE_CFG.get('beam_length_penalty', 0.0)\n",
    "    )\n",
    "    print('Live prediction:', ids_to_sentence(decoded[0], tokenizer))\n",
    "\n",
    "# decode_live_camera(seq2seq_model, tokenizer)  # Uncomment when pose extraction is wired up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58c98086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Live capture failed: Could not open webcam.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@7.345] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n"
     ]
    }
   ],
   "source": [
    "if 'seq2seq_model' not in globals():\n",
    "    raise RuntimeError('Model checkpoint not loaded. Run the cell that calls load_seq2seq_checkpoint first.')\n",
    "\n",
    "decode_live_camera(seq2seq_model, tokenizer)  # Requires cv2 + MediaPipe wired up\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signtalk_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
